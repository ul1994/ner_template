{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK expects sentences, so let's recover sentences from the .testb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format of the .train .test files:\n",
    "#\n",
    "# SOCCER NN I-NP O\n",
    "# ...\n",
    "#\n",
    "# (word) (Part of speech) (IOB2 tag) (end sequence character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685\n"
     ]
    }
   ],
   "source": [
    "with open('eng.testb') as fl:\n",
    "    sents = fl.read().split('\\n\\n')\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-DOCSTART- -X- -X- O', '')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0], sents[-1] # header, footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sents[1:-1]\n",
    "sents = [meta.split('\\n') for meta in sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARN: Don't join then re-tokenize the words b/c NLTK may produce a different tokenization than what is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SOCCER NN I-NP O', '- : O O', 'JAPAN NNP I-NP I-LOC', 'GET VB I-VP O', 'LUCKY NNP I-NP O', 'WIN NNP I-NP O', ', , O O', 'CHINA NNP I-NP I-PER', 'IN IN I-PP O', 'SURPRISE DT I-NP O', 'DEFEAT NN I-NP O', '. . O O']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SOCCER',\n",
       " '-',\n",
       " 'JAPAN',\n",
       " 'GET',\n",
       " 'LUCKY',\n",
       " 'WIN',\n",
       " ',',\n",
       " 'CHINA',\n",
       " 'IN',\n",
       " 'SURPRISE',\n",
       " 'DEFEAT',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recover_sent(meta):\n",
    "    # The first words compose a sentence (or a phrase)\n",
    "    \n",
    "    # TODO:\n",
    "\n",
    "    return words\n",
    "\n",
    "print(sents[0])\n",
    "recover_sent(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SOCCER', 'NNP', 'B-GPE'), ('-', ':', 'O'), ('JAPAN', 'NNP', 'B-ORGANIZATION'), ('GET', 'NNP', 'O'), ('LUCKY', 'NNP', 'O'), ('WIN', 'NNP', 'O'), (',', ',', 'O'), ('CHINA', 'NNP', 'B-GPE'), ('IN', 'NNP', 'O'), ('SURPRISE', 'NNP', 'O'), ('DEFEAT', 'NNP', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "test_me = recover_sent(sents[0])\n",
    "\n",
    "# HINT: use pos_tag, ne_chunk, and tree2conlltags from NLTK\n",
    "def sent2IOB(tkns):\n",
    "    # Uses conll tagger to get IOBs\n",
    "    \n",
    "    # TODO:\n",
    "    \n",
    "    return iob_tagged\n",
    "    \n",
    "print(sent2IOB(test_me))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The eng.train/test files use IOB1(?) such that only 4 tags (LOC, PER, ORG, MISC) + 1 null char (O) are used, but NLTK may return a few more ent types. \n",
    "\n",
    "<br>\n",
    "\n",
    "### If that's the case, think of a mapping to the 4 types so that we can run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "toIOB2 = {\n",
    "    # TODO: mappings by dictionary (FROM: TO)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below dumps your results into a .output file. Feel free to edit or replace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A reminder that conlleval.py expects each row to be `<word> <actual> <predicted>` with emtpy lines after each sentence)\n",
    "\n",
    "#### i.e.\n",
    "```\n",
    "SOCCER O B-LOC\n",
    "- O O\n",
    "JAPAN I-LOC B-ORG\n",
    "GET O O\n",
    "LUCKY O O\n",
    "WIN O O\n",
    ", O O\n",
    "CHINA I-PER B-LOC\n",
    "IN O O\n",
    "SURPRISE O O\n",
    "DEFEAT O O\n",
    ". O O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3682/3683]  \r"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "with open('eng_iob2.output', 'w') as fl:\n",
    "    for si, meta in enumerate(sents):\n",
    "        sent = recover_sent(meta)\n",
    "        iobs = sent2IOB(sent)\n",
    "        \n",
    "        assert len(iobs) is len(meta)\n",
    "        \n",
    "        for iob, inp in zip(iobs, meta):\n",
    "            # APPLY THE MAPPING\n",
    "            mapped_iob = iob[2]\n",
    "            if '-' in mapped_iob:\n",
    "                ichar, etype = mapped_iob.split('-')\n",
    "                mapped_iob = '%s-%s' % (ichar, toIOB2[etype])\n",
    "            fl.write('%s %s %s\\n' % (iob[0], inp.split()[3], mapped_iob))\n",
    "        fl.write('\\n')\n",
    "#         break\n",
    "        \n",
    "        sys.stdout.write('[%d/%d]  \\r' % (si, len(sents)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46665 tokens with 5648 phrases; found: 5384 phrases; correct: 2630.\r\n",
      "accuracy:  83.59%; precision:  48.85%; recall:  46.57%; FB1:  47.68\r\n",
      "              LOC: precision:  51.60%; recall:  70.38%; FB1:  59.55  2275\r\n",
      "             MISC: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "              ORG: precision:  32.09%; recall:  25.29%; FB1:  28.28  1309\r\n",
      "              PER: precision:  57.56%; recall:  64.07%; FB1:  60.64  1800\r\n"
     ]
    }
   ],
   "source": [
    "!python conlleval.py eng_iob2.output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
